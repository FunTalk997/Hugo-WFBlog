---
title: "Read and write process of HDFS"
date: 2022-08-22T01:47:25+08:00

# format for string: "xxxx-xx-xx"
# lastmod: "2022-10-01"

# set false when you want the post publish
draft: false
# one category: ["category-1"] 
# more categories: ["category-1", "category-2", ...]
categories: ['Hadoop']
# refer to categories
tags: ['Hadoop','HDFS']
# seires
series: ['Big Data']
# Top image for the post
image: "/images/postImg/hadoop.png"
# Hide from home page
hideFromHomePage: false
---

# HDFS Read Process

![photo](/images/posts/1661075245/image1.png)

1) The client calls the open() method of the DistributedFileSystem object to open the file to be read.
2) The DistributedFileSystem initiates an RPC call to the NameNode to obtain the data block information of the file and returns a list of data nodes. For each data block, the NameNode provides the address of the corresponding DataNode.
3) The DistributedFileSystem returns an FSDataInputStream object to the client, and the client calls the read() method of the FSDataInputStream object to start reading the data.
4) By repeatedly calling the read() method on the data stream, the data is transferred from the data nodes to the client.
5) When the data of a data block is fully read, the DFSInputStream object closes the connection with that data node and connects to the nearest data node for the next data block of the file.
6) When all the data of the file is read, the client calls the close() method of the DistributedFileSystem object to close the file input stream object.

# HDFS Write Process

![photo](/images/posts/1661075245/image2.png)

1) The client calls the create() method of the DistributedFileSystem object to create a file output stream object.
2) The DistributedFileSystem initiates an RPC call to the NameNode, which checks if the file already exists and if the client has permission to create a new file.
3) The DistributedFileSystem returns an FSDataOutputStream object to the client, and the client calls the write() method of the FSDataOutputStream object to write the data. The data is first written to a buffer and then split into individual data packets.
4) Each data packet is sent to a node in a group of data nodes assigned by the NameNode. The data packets are transmitted sequentially on the pipeline formed by the group of data nodes.
5) The data nodes on the pipeline return acknowledgment messages in the order of the pipeline. Eventually, the first data node on the pipeline returns the acknowledgment message for the entire pipeline to the client.
6) After the client finishes writing, it calls the close() method to close the file output stream object.
7) The NameNode is notified of the successful file write.