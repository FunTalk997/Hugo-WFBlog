---
title: "Elasticsearch installation and backup recovery"
date: 2022-11-08T16:11:06+08:00

# format for string: "xxxx-xx-xx"
# lastmod: "2022-10-01"

# set false when you want the post publish
draft: false
# one category: ["category-1"] 
# more categories: ["category-1", "category-2", ...]
categories: ['Elasticsearch']
# refer to categories
tags: ['Elasticsearch','Deploy','Backup','Recovery']
# seires
series: ['Middleware']
# Top image for the post
image: "/images/postImg/elasticsearch.png"
# Hide from home page
hideFromHomePage: false
---

# Offline Installation

## Download Elasticsearch Offline Installation Package

Elasticsearch Package:

Official Website: [https://www.elastic.co/cn/downloads/past-releases#elasticsearch](https://www.elastic.co/cn/downloads/past-releases#elasticsearch)

Download Link: [https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.8.1-linux-x86_64.tar.gz](https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.8.1-linux-x86_64.tar.gz)

IK Analyzer Package:

Download Link: [https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.8.1/elasticsearch-analysis-ik-7.8.1.zip](https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.8.1/elasticsearch-analysis-ik-7.8.1.zip)

```bash
curl -O https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.8.1-linux-x86_64.tar.gz
curl -O https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.8.1/elasticsearch-analysis-ik-7.8.1.zip

# Or
wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.8.1-linux-x86_64.tar.gz
wget https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.8.1/elasticsearch-analysis-ik-7.8.1.zip
```

## Upload to CentOS 7 Server and Extract

```bash
# Extract
tar -zxf elasticsearch-7.8.1-linux-x86_64.tar.gz -C /data

# Rename
mv elasticsearch-7.8.1 elasticsearch

# Create IK Analyzer Directory
mkdir -p /data/elasticsearch/plugins/ik

# Extract IK Analyzer to the IK Directory
unzip elasticsearch-analysis-ik-7.8.1.zip -d /data/elasticsearch/plugins/ik
```

## Modify Configuration

Modify Elasticsearch Configuration File

```bash
cat >> /data/elasticsearch/config/elasticsearch.yml << EOF
cluster.name: es-cluster
node.name: node1
path.data: /data/elasticsearch/data
path.logs: /data/elasticsearch/logs
network.host: 0.0.0.0
http.port: 9200
transport.port: 9300
cluster.initial_master_nodes: ["node1"]
path.repo: [/data/backup/es_backup]
EOF
```

Modify System Configuration

```shell
cat >> /etc/security/limits.conf << EOF
elastic	soft	nofile	65535
elastic	hard	nofile	65535
EOF
```

## Create ES User and Grant Permissions

```bash
# Create ES User Group
groupadd -g 2000 elastic

# Create a User Named "elastic" and Add it to the ES User Group
useradd -u 2000 -g elastic elastic

# Grant Permissions for ES Installation Directory to the elastic User
chown -R elastic.elastic /data/elasticsearch

# Create ES Backup Directory
mkdir -p /data/backup/es_backup

# Grant Permissions for ES Backup Directory to the elastic User
chown -R elastic.elastic /data/backup/es_backup
```

## Start Elasticsearch

```bash
# Start Elasticsearch
su - elastic
/data/elasticsearch/bin/elasticsearch -d
exit

# Stop Elasticsearch
netstat -tulpn | grep 9200 | awk '{print $NF}' | awk -F'/' '{print $1}' | xargs kill -9
```

Elasticsearch Start/Stop Script

```bash
#! /bin/bash
#   
# mongodb - this script starts and stops the mongodb daemon
#   
# chkconfig:    2345 80 90
# description:  mongodb is a persistent key-value database
#   
### BEGIN INIT INFO
# Provides:          mongodb
# Required-Start:    $syslog
# Required-Stop:     $syslog
# Should-Start:        $local_fs
# Should-Stop:        $local_fs
# Default-Start:     2 3 4 5
# Default-Stop:      0 1 6
# Short-Description:    mongodb daemon
# Description:        mongodb daemon
### END INIT INFO

APP_NAME=elasticsearch
PORT=9200
APP_HOME=$(cd $(dirname $0);pwd)
EXEC=$APP_HOME/bin/elasticsearch
#CONF=$APP_HOME/conf/mongod.conf
CONSOLE_LOG=$APP_HOME/logs/$APP_console.log
START_CMD="$EXEC -d"
# Get Process PID
PID=`netstat -tulpn | grep $PORT | awk '{print $NF}' |awk -F'/' '{print $1}'`
STOP_CMD="kill -9 $PID"
START_USER=elastic
case "$1" in
    start)
        if [ $PID ];then
            if netstat -tnpl | grep -q $PORT;then
                echo "$APP_NAME is already running"
            else
                echo "$APP_NAME port not listening"
            fi
        else
            echo "$APP_NAME Starting ..."
            su - $START_USER -c "$START_CMD"
            sleep 2
            for((i=1;i<=60;i++));
            do
                ps -ef | grep -w $APP_NAME | grep -v grep > /dev/null 2>&1
                if [ $? = 0 ] ; then
                    #nc -w 3 ${HOST_NAME} $ACTIVE_PORT < /dev/null > /dev/null 2>&1
                    if netstat -tnpl | grep -q $PORT;then
                        echo "$APP_NAME start done"
                        exit 0
                    else
                        if [ $i = 170 ];then
                            echo "$APP_NAME start failed"
                            exit 1
                        fi
                    fi
                else
                    echo "$APP_NAME process is not running..."
                    echo "$APP_NAME start failed"
                    exit 1
                fi
                sleep 1
            done
        fi
        ;;
    stop)
        if [ $PID ];then
            echo "$APP_NAME Stoping..."
            $STOP_CMD
            if [ $? = 0 ]; then
                echo "$APP_NAME stop done"
            else
                echo "$APP_NAME stop failed"
            fi
        else
            echo "$APP_NAME is not running"
        fi
        ;;
    restart)
        cd $APP_HOME
        sh ${0} stop
        sleep 2
        sh ${0} start
        ;;
    status)
        if netstat -tnpl | grep -q $PORT;then
            echo "$APP_NAME is running."
        else
            echo "$APP_NAME is stopped."
        fi
        ;;
  *)
    echo "Usage: $APP_HOME/run.sh {start|stop|restart|status}" >&2
        exit 1
esac
```

# Elasticsearch Data Backup and Restore

## Elasticsearch Data Backup

### Create Elasticsearch Backup Directory

```bash
mkdir /data/backup/es_backup
```

### Grant Permissions for ES Backup Directory to the elastic User

```bash
chown -R elastic.elastic /data/backup/es_backup
```

### Modify ES Configuration File (Restart ES after Modification)

```bash
cat >> /data/elasticsearch/config/elasticsearch.yml << EOF
path.repo: [ "/data/backup/es_backup" ]
EOF
```

### Create Elasticsearch Repository

```bash
curl -XPOST 'http://127.0.0.1:9200/_snapshot/my_backup' -H "Content-Type: application/json" -d '{
	"type": "fs",
	"settings": {
  	"location": "/data/backup/es_backup",
    }
}'
```

### Backup All Index Data

```bash
# wair_for_completion=true: Run the snapshot as a background process
curl -XPUT 'http://127.0.0.1:9200/_snapshot/my_backup/snapshot_1?wait_for_completion=true'
```

### Backup Specific Indexes

```bash
curl -XPUT 'http://127.0.0.1:9200/_snapshot/my_backup/snapshot_2?wait_for_completion=true' -H "Content-Type: application/json" -d '{
	"indices": "index_1,index_2",
	"ignore_unavailable": true
}'
```

### View All Backup Results

```bash
curl -XGET 'http://127.0.0.1:9200/_snapshot/my_backup/_all?pretty'
```

### View Individual Backup Result

```bash
curl -XGET 'http://127.0.0.1:9200/_snapshot/my_backup/snapshot_1'
curl -XGET 'http://127.0.0.1:9200/_snapshot/my_backup/snapshot_2'
```

### Delete Snapshot

```bash
curl -XDELETE 'http://127.0.0.1:9200/_snapshot/my_backup/snapshot2'
```

### Backup es_backup Directory

```bash
cp -r /data/backup/es_backup /data/backup/es_snapshot/bak_2022-10-25
tar -zcf es_2022-10-25.tar.gz /data/backup/es_snapshot/bak_2022-10-25 --remove-files
```

### Backup Script:

```bash
#!/bin/bash

################### Common Variables ######################
DATE=$(date '+%Y-%m-%d-%H-%M')
BACK_DIR=/data/backup
SAVE_DATE=7

########### Elasticsearch Variable Parameters #################
ES_Local_DIR=$BACK_DIR/es_snapshot/bak_${DATE}
ES_IP=192.168.14.201
ES_PORT=9200
ES_Indices="conductor_message_20221001,conductor_task,conductor_message_20221002,script_log,form_log,conductor_workflow,.kibana_task_manager_1,bpms-operation_logoperationmodel,monitor-event-interface,bpms-integration_logopenapientity,conductor_message_20221003,conductor_message_20221004,test,conductor_event_20220805,.apm-agent-configuration,conductor_event_20220804,script_result,bpms-operation_businessoperationmodel,bpms-integration_logcallbackentity,mini_program_audit_entity,conductor_message_20220905,conductor_message_20220903,conductor_message_20220904,conductor_message_20220901,conductor_message_20220902,messages,bpms-operation_appactiveindexmodel,workflow_change_log_entity,monitor-event-transaction,er_operation_log,application_access_log,conductor_event_20220904,conductor_event_20220905,conductor_event_20220901,conductor_event_20220902,conductor_event_20220903,.kibana_1,conductor_event_20221002,workflow_global-change_log_entity,conductor_event_20221003,conductor_event_20221004,conductor_message_20220804,conductor_message_20220805,bpms-operation_activeindexmodel,conductor_event_20221001"
ES_AUTH=False
ES_PASSWD=''
Es_TARNAME=test_es
# Backup Directory
Es_NEW_DIR=$BACK_DIR/es_backup

function delete_index() {
  check_day=$(date -d '-7 days' '+%Y-%m-%d')
  index_day=$1
  # Convert the date to a timestamp
  check_day_timestamp=$(date -d "$check_day" +%s)
  index_day_timestamp=$(date -d "$index_day" +%s)
  if [ "${index_day_timestamp}" -lt "${check_day_timestamp}" ]; then
    if [ ${ES_AUTH} = "False" ]; then
      curl -XDELETE http://${ES_IP}:${ES_PORT}/_snapshot/EsBackup/bak_"$LINE"
    else
      curl -u elastic:"${ES_PASSWD}" -XDELETE http://${ES_IP}:${ES_PORT}/_snapshot/EsBackup/bak_"$LINE"
    fi
  fi
}

function ES_backup() {
  INDEX_DATE=$(date '+%Y-%m-%d')
  test ! -d ./log/es && mkdir -p ./log/es
  # Perform backup
  if [ ${ES_AUTH} = "False" ]; then
    curl -XPUT http://${ES_IP}:${ES_PORT}/_snapshot/EsBackup/bak_"${INDEX_DATE}"?wait_for_completion=true -H 'Content-Type: application/json' -d '{"indices":"'"${ES_Indices}"'","ignore_unavailable": true}'
  else
    curl -u elastic:"${ES_PASSWD}" -XPUT http://${ES_IP}:${ES_PORT}/_snapshot/EsBackup/bak_"${INDEX_DATE}"?wait_for_completion=true -H 'Content-Type: application/json' -d '{"indices":"'"${ES_Indices}"'","ignore_unavailable": true}'
  fi

  test ! -d $BACK_DIR/es_snapshot && mkdir -p $BACK_DIR/es_snapshot

  # Keep snapshot files for 7 days
  if [ ${ES_AUTH} = "False" ]; then
    # shellcheck disable=SC2162
    curl -s -XGET http://${ES_IP}:${ES_PORT}/_snapshot/EsBackup/_all?pretty | grep bak | awk -F"," '{print $1}' | awk -F" " '{print $3}' | sed 's/"//g' | awk -F"_" '{print $2}' | sort | uniq | while read LINE; do
      delete_index "$LINE"
    done
  else
    # shellcheck disable=SC2162
    curl -s -XGET -u elastic:"${ES_PASSWD}" http://${ES_IP}:${ES_PORT}/_snapshot/EsBackup/_all?pretty | grep bak | awk -F"," '{print $1}' | awk -F" " '{print $3}' | sed 's/"//g' | awk -F"_" '{print $2}' | sort | uniq | while read LINE; do
      delete_index "$LINE"
    done
  fi

  cp -r ${Es_NEW_DIR} "${ES_Local_DIR}"
  tar -zcf $BACK_DIR/es_snapshot/${Es_TARNAME}_"${DATE}".tar.gz "${ES_Local_DIR}" --remove-files >>./log/es/es_backup_"${DATE}".log 2>&1

  # shellcheck disable=SC2181
  if [ $? -eq 0 ]; then
    # shellcheck disable=SC2006
    STATUS=$(curl http://${ES_IP}:${ES_PORT}/_snapshot/EsBackup/bak_"${INDEX_DATE}"?pretty)
    if [[ ${STATUS} =~ "SUCCESS" ]]; then
      echo 'ES backup successful!!!'
      curl 'https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=166b53e1-90c9-4581-b797-85dcfe4e0536' \
        -H 'Content-Type: application/json' \
        -d '
   {
        "msgtype": "markdown",
        "markdown": {
            "content": "<font color=\"info\">'"${ES_IP}:${ES_PORT}"'-ES backup successful!!!'"$(date '+%Y-%m-%d %H:%M:%S')"'</font>"
        }
   }'

    else
      echo "ES backup failed!!!"
      curl 'https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=166b53e1-90c9-4581-b797-85dcfe4e0536' \
        -H 'Content-Type: application/json' \
        -d '
   {
        "msgtype": "markdown",
        "markdown": {
            "content": "<font color=\"warning\">'"${ES_IP}:${ES_PORT}"'-ES backup failed!!!'"$(date '+%Y-%m-%d %H:%M:%S')"'</font>"
        }
   }'
    fi

  else
    echo "ES backup failed!!!"
    curl 'https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=166b53e1-90c9-4581-b797-85dcfe4e0536' \
      -H 'Content-Type: application/json' \
      -d '
   {
        "msgtype": "markdown",
        "markdown": {
            "content": "<font color=\"warning\">'"${ES_IP}:${ES_PORT}"'-ES backup failed!!!'"$(date '+%Y-%m-%d %H:%M:%S')"'</font>"
        }
   }'
  fi

  find $BACK_DIR/es_snapshot/ -type f -mtime +${SAVE_DATE} -name "*.tar.gz" -exec rm -f {} \;
}

echo "Start Elasticsearch backup..."
curl 'https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=166b53e1-90c9-4581-b797-85dcfe4e0536' \
  -H 'Content-Type: application/json' \
  -d '
   {
        "msgtype": "markdown",
        "markdown": {
            "content": "<font color=\"info\">'"${ES_IP}"'-Start Elasticsearch backup!!!'"$(date '+%Y-%m-%d %H:%M:%S')"'</font>"
        }
   }'
ES_backup


```

## Elasticsearch Data Restore

### Restore Snapshot for All Indexes

```bash
curl -XPOST 'http://127.0.0.1:9200/_snapshot/my_backup/snapshot_1/_restore'
```

### Restore Snapshot for Specific Indexes

```bash
curl -XPOST 'http://127.0.0.1:9200/_snapshot/mybackup/snapshot_1/_resore' -H "Content-Type: application/json" -d '{
	"indices": "index_1,index_2",
	"rename_parttern": "index_(.x)",
	"rename_replacement": "restored_index_$1"
}'
```

- indices: Only restore the index_1 index and ignore other indexes present in the snapshot.
- rename_parttern: Find the patterns that match the indexes being restored.
- rename_replacement: Rename them to the specified replacement pattern.

### Delete Restore

```bash
curl -XDELETE 'http://127.0.0.1:9200/restored_index_3'
```
